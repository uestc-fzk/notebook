# see kafka.server.KafkaConfig for additional details and defaults

############################# Server Basics #############################

# broker的id，必须唯一
broker.id=0

############################# Socket Server Settings #############################

# The address the socket server listens on. It will get the value returned from 
# java.net.InetAddress.getCanonicalHostName() if not configured.
#   FORMAT:
#     listeners = listener_name://host_name:port
#   EXAMPLE:
#     listeners = PLAINTEXT://your.host.name:9092
#listeners=PLAINTEXT://:9092

# Hostname and port the broker will advertise to producers and consumers. If not set, 
# it uses the value for "listeners" if configured.  Otherwise, it will use the value
# returned from java.net.InetAddress.getCanonicalHostName().
#advertised.listeners=PLAINTEXT://your.host.name:9092

# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details
#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL

# server接受请求和发送响应的线程数量
num.network.threads=3

# server处理请求的线程数量，包括磁盘IO处理
num.io.threads=8

# socket server的发送缓冲区(SO_SNDBUF)
socket.send.buffer.bytes=102400

# socket server的接受缓冲区(SO_RCVBUF)
socket.receive.buffer.bytes=102400

# socket server能接受的最大请求大小(protection against OOM)
socket.request.max.bytes=104857600


############################# Log Basics #############################

# 以逗号分隔的目录列表，用于存储日志文件
log.dirs=/tmp/kafka-logs

# 每个topic的默认日志partitions数量。
# 更多的分区允许更多的并行性，也会导致brokers之间产生更多的文件
num.partitions=1

# 每个数据目录中用于启动时日志恢复和关闭时刷新的线程数。对于数据目录位于RAID阵列中的安装，建议增加此值。
num.recovery.threads.per.data.dir=1

############################# Internal Topic Settings  #############################
# 组内数据内部topics "__consumer_offsets" and "__transaction_state"的复制系数，对于开发测试以外的任何测试都应该大于1以确保可用性，如3
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1

############################# Log 刷新 Policy #############################

# 消息会立即写入文件系统，默认情况下，只使用fsync()延迟同步操作系统缓存。
# 以下配置控制数据刷新到磁盘策略，有几个重要的权衡：
#   1.持久性：如果不使用复制，未刷新的数据可能会丢失。
#   2.延迟：非常大的刷新时间间隔可能会导致刷新出现延迟峰值
#   3.吞吐量：刷新通常是最昂贵的操作，较小的刷新间隔可能会导致过度搜索。
# 下面的设置允许用户配置刷新策略，在一段时间后或每N条消息（或两者）刷新一次数据。这可以在全局范围内完成，并在每个主题的基础上覆盖。

# 接受消息数量达到此，将强制刷新数据到磁盘
#log.flush.interval.messages=10000

# 在强制刷新之前，消息在日志中的最长时间
#log.flush.interval.ms=1000

############################# Log 保留 Policy #############################

# 以下配置控制log segments的处理，策略可以设置为一定时间后或者给定大小积累后删除log segments。
# 只要满足其一就会删除，总是从日志的末尾开始删除。

# 日志的最小删除年龄
log.retention.hours=168

# 基于大小的日志保留策略。日志大小超过此限制，将对日志进行剪枝。此策略独立于上面这个 log.retention.hours.
#log.retention.bytes=1073741824

# log segment的最大大小，达到后将创建新的log segment
log.segment.bytes=1073741824

# 检查日志段以确定是否可以根据保留策略删除它们的时间间隔
log.retention.check.interval.ms=300000

############################# Zookeeper #############################

# Zookeeper连接地址，以逗号分隔host:port，每个对应一个zookeeper服务器节点
# You can also append an optional chroot string to the urls to specify the root directory for all kafka znodes
zookeeper.connect=localhost:2181

# zookeeper连接超时限制
zookeeper.connection.timeout.ms=18000


############################# Group Coordinator Settings #############################

# 以下配置指定GroupCoordinator延迟初始使用者重新平衡的时间(ms)。
# 由于group的价值，再平衡将进一步推迟group.initial.rebalance.delay.ms作为新成员加入该组，最多可达max.poll.interval.ms.
# 默认值为3秒。
# 我们在这里将其覆盖为0，因为这有助于为开发和测试提供更好的开箱即用体验。
# 但是，在生产环境中，3秒的默认值更合适，因为这将有助于避免在应用程序启动期间进行不必要且可能代价高昂的重新平衡。
group.initial.rebalance.delay.ms=0
